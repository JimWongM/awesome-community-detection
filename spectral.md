
## Spectral Methods

- **1.Spectral Clustering by Subspace Randomization and Graph Fusion for High-Dimensional Data (PAKDD 2020)**
  - Xiaosha Cai, Dong Huang, Chang-Dong Wang, Chee-Keong Kwoh
  - [[Paper]](https://www.researchgate.net/publication/338864070_Spectral_Clustering_by_Subspace_Randomization_and_Graph_Fusion_for_High-Dimensional_Data)
  - [[Matlab Reference]](https://github.com/huangdonghere/SC-SRGF)

Subspace clustering has been gaining increasing attention in recent years due to its promising ability in dealing with high-dimensional data. However, most of the existing subspace clustering methods tend to only exploit the subspace information to construct a single affinity graph (typically for spectral clustering), which often lack the ability to go beyond a single graph to explore multiple graphs built in various subspaces in high-dimensional space. To address this, this paper presents a new spectral clustering approach based on subspace randomization and graph fusion (SC-SRGF) for high-dimensional data. In particular, a set of random subspaces are first generated by performing random sampling on the original feature space. Then, multiple K-nearest neighbor (K-NN) affinity graphs are constructed to capture the local structures in the generated subspaces. To fuse the multiple affinity graphs from multiple subspaces, an iterative similarity network fusion scheme is utilized to achieve a unified graph for the final spectral clustering. Experiments on twelve real-world high-dimensional datasets demonstrate the superiority of the proposed approach. The MATLAB source code is available at https://www.researchgate.net/publication/338864134.

- **2.Spectral Clustering in Heterogeneous Information Networks (AAAI 2019)**
  - Xiang Li, Ben Kao, Zhaochun Ren, Dawei Yin
  - [[Paper]](https://www.aaai.org/ojs/index.php/AAAI/article/view/4328)
  - [[Matlab Reference]](https://github.com/lixiang3776/SClump)
  - [[Python Reference]](https://github.com/ameya98/PySClump)

A heterogeneous information network (HIN) is one whose objects are of different types and links between objects could model different object relations. We study how spectral clustering can be effectively applied to HINs. In particular, we focus on how meta-path relations are used to construct an effective similarity matrix based on which spectral clustering is done. We formulate the similarity matrix construction as an optimization problem and propose the SClump algorithm for solving the problem. We conduct extensive experiments comparing SClump with other state-of-the-art clustering algorithms on HINs. Our results show that SClump outperforms the competitors over a range of datasets w.r.t. different clustering quality measures.

- **3.Community Detection Over a Heterogeneous Population of Non-aligned Networks (Arxiv 2019)**
  - Guilherme Gomes, Vinayak Rao, Jennifer Neville
  - [[Paper]](https://arxiv.org/abs/1904.05332)
  - [[Python Reference]](https://github.com/kurtmaia/JointSBM)

Clustering and community detection with multiple graphs have typically focused on aligned graphs, where there is a mapping between nodes across the graphs (e.g., multi-view, multi-layer, temporal graphs). However, there are numerous application areas with multiple graphs that are only partially aligned, or even unaligned. These graphs are often drawn from the same population, with communities of potentially different sizes that exhibit similar structure. In this paper, we develop a joint stochastic blockmodel (Joint SBM) to estimate shared communities across sets of heterogeneous non-aligned graphs. We derive an efficient spectral clustering approach to learn the parameters of the joint SBM. We evaluate the model on both synthetic and real-world datasets and show that the joint model is able to exploit cross-graph information to better estimate the communities compared to learning separate SBMs on each individual graph.

- **4.Spectral Rejection for Testing Hypotheses of Structure in Networks (Arxiv 2019)**
  - Mark D. Humphries, Javier A. Caballero, Mat Evans, Silvia Maggi, Abhinav Singh
  - [[Paper]](https://arxiv.org/abs/1901.04747)
  - [[Matlab Reference]](https://github.com/mdhumphries/NetworkNoiseRejection)
  - [[Python Reference]](https://github.com/thomasjdelaney/Network_Noise_Rejection_Python)

Discovering structure in real-world networks requires a suitable null model that defines the absence of meaningful structure. Here we introduce a spectral approach for testing structural hypotheses at both network and node levels, by using generative models to estimate the eigenvalue distribution under a specified null model. On synthetic networks, this spectral rejection approach cleanly detects transitions between random and community structure, recovers the number and membership of communities, and removes noise nodes. On real networks spectral rejection finds either a significant fraction of noise nodes or no departure from a null model, in stark contrast to traditional community detection methods. Across all analyses, we find the choice of null model can strongly alter conclusions about the presence of network structure. Our spectral rejection approach is therefore a promising way to reveal structure in real-world networks, or lack thereof.

- **5.Spectral Clustering of Signed Graphs via Matrix Power Means (ICML 2019)**
  - Pedro Mercado, Francesco Tudisco, Matthias Hein
  - [[Paper]](https://arxiv.org/pdf/1905.06230v1.pdf)
  - [[Matlab Reference]](https://github.com/melopeo/SPM)

Signed graphs encode positive (attractive) and
negative (repulsive) relations between nodes. We
extend spectral clustering to signed graphs via
the one-parameter family of Signed Power Mean
Laplacians, defined as the matrix power mean
of normalized standard and signless Laplacians
of positive and negative edges. We provide a
thorough analysis of the proposed approach in
the setting of a general Stochastic Block Model
that includes models such as the Labeled Stochastic Block Model and the Censored Block Model.
We show that in expectation the signed power
mean Laplacian captures the ground truth clusters under reasonable settings where state-of-theart approaches fail. Moreover, we prove that the
eigenvalues and eigenvector of the signed power
mean Laplacian concentrate around their expectation under reasonable conditions in the general
Stochastic Block Model. Extensive experiments
on random graphs and real world datasets confirm
the theoretically predicted behaviour of the signed
power mean Laplacian and show that it compares
favourably with state-of-the-art methods.

- **6.A Unified Framework for Structured Graph Learning via Spectral Constraints (ArXiv 2019)**
  - Sandeep Kumar, Jiaxi Ying, José Vinícius de Miranda Cardoso, and Daniel Palomar
  - [[Paper]](https://arxiv.org/pdf/1904.09792.pdf)
  - [[R Reference]](https://cran.r-project.org/web/packages/spectralGraphTopology/index.html)

Graph learning from data represents a canonical problem that has received substantial attention in the literature. However, insufficient work has been done in incorporating prior
structural knowledge onto the learning of underlying graphical models from data. Learning
a graph with a specific structure is essential for interpretability and identification of the
relationships among data. Useful structured graphs include the multi-component graph,
bipartite graph, connected graph, sparse graph, and regular graph. In general structured
graph learning is an NP-hard combinatorial problem therefore designing a general tractable
optimization method is extremely challenging. In this paper, we introduce a unified graph
learning framework lying at the integration of Gaussian graphical models and spectral
graph theory. To impose a particular structure on a graph, we first show how to formulate the combinatorial constraints as an analytical property of the graph matrix. Then we
develop an optimization framework that leverages graph learning with specific structures
via spectral constraints on graph matrices. The proposed algorithms are provably convergent, computationally efficient, and practically amenable for numerous graph-based tasks.
Extensive numerical experiments with both synthetic and real data sets illustrate the effectiveness of the proposed algorithms. The code for all the simulations is made available
as open source repository.


- **7.An Ensemble Based on a Bi-objective Evolutionary Spectral Algorithm for Graph Clutering (ArXiv 2018)**
  - Camila P.S. Tautenhain, Mariá C.V. Nascimento
  - [[Paper]](https://arxiv.org/abs/1810.03652)
  - [[C++ Reference]](https://github.com/camilapsan/MOSpecG_SpecG)

Graph clustering is a challenging pattern recognition problem whose goal is to identify vertex partitions with high intra-group connectivity. This paper investigates a bi-objective problem that maximizes the number of intra-cluster edges of a graph and minimizes the expected number of inter-cluster edges in a random graph with the same degree sequence as the original one. The difference between the two investigated objectives is the definition of the well-known measure of graph clustering quality: the modularity. We introduce a spectral decomposition hybridized with an evolutionary heuristic, called MOSpecG, to approach this bi-objective problem and an ensemble strategy to consolidate the solutions found by MOSpecG into a final robust partition. The results of computational experiments with real and artificial LFR networks demonstrated a significant improvement in the results and performance of the introduced method in regard to another bi-objective algorithm found in the literature. The crossover operator based on the geometric interpretation of the modularity maximization problem to match the communities of a pair of individuals was of utmost importance for the good performance of MOSpecG. Hybridizing spectral graph theory and intelligent systems allowed us to define significantly high-quality community structures.

- **8.Hierarchical Community Detection by Recursive Partitioning (ArXiv 2018)**
  - Tianxi Li, Lihua Lei, Sharmodeep Bhattacharyya, Purnamrita Sarkar, Peter J. Bickel, Elizaveta Levina
  - [[Paper]](https://arxiv.org/abs/1810.01509)
  - [[R Reference]](https://github.com/tianxili/HCD)  

The problem of community detection in networks is usually formulated as finding a single partition of the network into some "correct" number of communities. We argue that it is more interpretable and in some regimes more accurate to construct a hierarchical tree of communities instead. This can be done with a simple top-down recursive partitioning algorithm, starting with a single community and separating the nodes into two communities by spectral clustering repeatedly, until a stopping rule suggests there are no further communities. This class of algorithms is model-free, computationally efficient, and requires no tuning other than selecting a stopping rule. We show that there are regimes where this approach outperforms K-way spectral clustering, and propose a natural framework for analyzing the algorithm's theoretical performance, the binary tree stochastic block model. Under this model, we prove that the algorithm correctly recovers the entire community tree under relatively mild assumptions. We also apply the algorithm to a dataset of statistics papers to construct a hierarchical tree of statistical research communities.

- **9.Scalable Spectral Clustering Using Random Binning Features (KDD 2018)**
  - Lingfei Wu, Pin-Yu Chen, Ian En-Hsu Yen, Fangli Xu, Yinglong Xia, and Charu Aggarwal 
  - [[Paper]](https://arxiv.org/abs/1805.11048)
  - [[Matlab Reference]](https://github.com/IBM/SpectralClustering_RandomBinning)

Spectral clustering is one of the most effective clustering approaches that capture hidden cluster structures in the data. However, it does not scale well to large-scale problems due to its quadratic complexity in constructing similarity graphs and computing subsequent eigendecomposition. Although a number of methods have been proposed to accelerate spectral clustering, most of them compromise considerable information loss in the original data for reducing computational bottlenecks. In this paper, we present a novel scalable spectral clustering method using Random Binning features (RB) to simultaneously accelerate both similarity graph construction and the eigendecomposition. Specifically, we implicitly approximate the graph similarity (kernel) matrix by the inner product of a large sparse feature matrix generated by RB. Then we introduce a state-of-the-art SVD solver to effectively compute eigenvectors of this large matrix for spectral clustering. Using these two building blocks, we reduce the computational cost from quadratic to linear in the number of data points while achieving similar accuracy. Our theoretical analysis shows that spectral clustering via RB converges faster to the exact spectral clustering than the standard Random Feature approximation. Extensive experiments on 8 benchmarks show that the proposed method either outperforms or matches the state-of-the-art methods in both accuracy and runtime. Moreover, our method exhibits linear scalability in both the number of data samples and the number of RB features.

- **10.Understanding Regularized Spectral Clustering via Graph Conductance (NIPS 2018)**
  - Yilin Zhang and Karl Rohe
  - [[Paper]](https://arxiv.org/abs/1806.01468)
  - [[Python Reference]](https://github.com/crisbodnar/regularised-spectral-clustering)

This paper uses the relationship between graph conductance and spectral clustering to study (i) the failures of spectral clustering and (ii) the benefits of regularization. The explanation is simple. Sparse and stochastic graphs create a lot of small trees that are connected to the core of the graph by only one edge. Graph conductance is sensitive to these noisy `dangling sets'. Spectral clustering inherits this sensitivity. The second part of the paper starts from a previously proposed form of regularized spectral clustering and shows that it is related to the graph conductance on a `regularized graph'. We call the conductance on the regularized graph CoreCut. Based upon previous arguments that relate graph conductance to spectral clustering (e.g. Cheeger inequality), minimizing CoreCut relaxes to regularized spectral clustering. Simple inspection of CoreCut reveals why it is less sensitive to small cuts in the graph. Together, these results show that unbalanced partitions from spectral clustering can be understood as overfitting to noise in the periphery of a sparse and stochastic graph. Regularization fixes this overfitting. In addition to this statistical benefit, these results also demonstrate how regularization can improve the computational speed of spectral clustering. We provide simulations and data examples to illustrate these results.

- **11.Locally-Biased Spectral Approximation for Community Detection (Knowledge-Based Systems 2018)**
  - Pan Shi, Kun He, David Bindel, and John Hopcroft
  - [[Paper]](https://pdfs.semanticscholar.org/d9e2/598b261a61c69d970e1c9eab7a50da4e458c.pdf)
  - [[Matlab Reference]](https://github.com/PanShi2016/LBSA)

We propose a Locally-Biased Spectral Approximation (LBSA) approach for identifying all latent members of a local community from very few seed members. To reduce the computation complexity, we first apply a fast random walk, personalized PageRank and heat kernel diffusion to sample a comparatively small subgraph covering almost all potential community members around the seeds. Then starting from a normalized indicator vector of the seeds and by a few steps of either Lanczos iteration or power iteration on the sampled subgraph, a local eigenvector is gained for approximating the eigenvector of the transition matrix with the largest eigenvalue. Elements of this local eigenvector is a relaxed indicator for the affiliation probability of the corresponding nodes to the target community. We conduct extensive experiments on real-world datasets in various domains as well as synthetic datasets. Results show that the proposed method outperforms state-of-the-art local community detection algorithms. To the best of our knowledge, this is the first work to adapt the Lanczos method for local community detection, which is natural and potentially effective. Also, we did the first attempt of using heat kernel as a sampling method instead of detecting communities directly, which is proved empirically to be very efficient and effective

- **12.Community Detection on Euclidean Random Graphs (Electronic Journal of Statistics 2018)**
  - Abishek Sankararaman and Francois Baccelli
  - [[Paper]](http://abishek90.github.io/CommDet.pdf)
  - [[Python Reference]](https://github.com/abishek90/Community-Detection-on-a-Spatial-Graph)

We study the problem of community detection on Euclidean random geometric graphs where
each vertex has two latent variables: a binary community label and a R
d valued location label
which forms the support of a Poisson point process of intensity λ. A random graph is then drawn
with edge probabilities dependent on both the community and location labels. In contrast to
the stochastic block model (SBM) that has no location labels, the resulting random graph
contains many more short loops due to the geometric embedding. We consider the recovery of
the community labels, partial and exact, using the random graph and the location labels. We
establish phase transitions for both sparse and logarithmic degree regimes, and provide bounds
on the location of the thresholds, conjectured to be tight in the case of exact recovery. We also
show that the threshold of the distinguishability problem, i.e., the testing between our model
and the null model without community labels exhibits no phase-transition and in particular,
does not match the weak recovery threshold (in contrast to the SBM)

- **13.Community Detection by L0-Penalized Graph Laplacian (Electronic Journal of Statistics 2018)**
  - Chong Chen, Ruibin Xi, and Nan Lin
  - [[Paper]](https://projecteuclid.org/euclid.ejs/1528769122)
  - [[Matlab Reference]](https://github.com/ChongC1990/L0Lap)

Community detection in network analysis aims at partitioning nodes into disjoint communities. Real networks often contain outlier nodes that do not belong to any communities and often do not have a known number of communities. However, most current algorithms assume that the number of communities is known and even fewer algorithm can handle networks with outliers. In this paper, we propose detecting communities by maximizing a novel model free tightness criterion. We show that this tightness criterion is closely related with the L0-penalized graph Laplacian and develop an efficient algorithm to extract communities based on the criterion. Unlike many other community detection methods, this method does not assume the number of communities is known and can properly detect communities in networks with outliers. Under the degree corrected stochastic block model, we show that even for networks with outliers, maximizing the tightness criterion can extract communities with small misclassification rates when the number of communities grows to infinity as the network size grows. Simulation and real data analysis also show that the proposed method performs significantly better than existing methods.

- **14.Phase Transitions and a Model Order Selection Criterion for Spectral Graph Clustering (IEEE TSP 2018)**
  - Pin-Yu Chen and Alfred O. Hero
  - [[Paper]](https://arxiv.org/abs/1604.03159)
  - [[Python Reference]](https://github.com/tgensol/AMOS)

One of the longstanding open problems in spectral graph clustering (SGC) is the so-called model order selection problem: automated selection of the correct number of clusters. This is equivalent to the problem of finding the number of connected components or communities in an undirected graph. We propose automated model order selection (AMOS), a solution to the SGC model selection problem under a random interconnection model (RIM) using a novel selection criterion that is based on an asymptotic phase transition analysis. AMOS can more generally be applied to discovering hidden block diagonal structure in symmetric non-negative matrices. Numerical experiments on simulated graphs validate the phase transition analysis, and real-world network data is used to validate the performance of the proposed model selection procedure.

- **15.An Algorithm J-SC of Detecting Communities in Complex Networks (Physics Letters A 2017)**
  - Fang Hu, Mingzhu Wang, Yanran Wang, Zhehao Hong, and Yanhui Zhu
  - [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S0375960117308678)
  - [[Matlab reference]](https://github.com/yanhueiju/community_detection_J-SC)

Currently, community detection in complex networks has become a hot-button topic. In this paper, based on the Spectral Clustering (SC) algorithm, we introduce the idea of Jacobi iteration, and then propose a novel algorithm J-SC for community detection in complex networks. Furthermore, the accuracy and efficiency of this algorithm are tested by some representative real-world networks and several computer-generated networks. The experimental results indicate that the J-SC algorithm can accurately and effectively detect the community structure in these networks. Meanwhile, compared with the state-of-the-art community detecting algorithms SC, SOM, K-means, Walktrap and Fastgreedy, the J-SC algorithm has better performance, reflecting that this new algorithm can acquire higher values of modularity and NMI. Moreover, this new algorithm has faster running time than SOM and Walktrap algorithms.

- **16.Local Lanczos Spectral Approximation for Community Detection (ECML PKDD 2017)**
  - Pan Shi, He Kun, David Bindel, and John Hopcroft
  - [[Paper]](http://ecmlpkdd2017.ijs.si/papers/paperID161.pdf)
  - [[Python Reference]](https://github.com/PanShi2016/LLSA)

We propose a novel approach called the Local Lanczos Spectral Approximation (LLSA) for identifying all latent members of a local
community from very few seed members. To reduce the computation
complexity, we first apply a fast heat kernel diffusing to sample a comparatively small subgraph covering almost all possible community members around the seeds. Then starting from a normalized indicator vector
of the seeds and by a few steps of Lanczos iteration on the sampled
subgraph, a local eigenvector is gained for approximating the eigenvector of the transition matrix with the largest eigenvalue. Elements of this
local eigenvector is a relaxed indicator for the affiliation probability of
the corresponding nodes to the target community. We conduct extensive experiments on real-world datasets in various domains as well as
synthetic datasets. Results show that the proposed method outperforms
state-of-the-art local community detection algorithms. To the best of our
knowledge, this is the first work to adapt the Lanczos method for local
community detection, which is natural and potentially effective. Also, we
did the first attempt of using heat kernel as a sampling method instead
of detecting communities directly, which is proved empirically to be very
efficient and effective.

- **17.AMOS: An Automated Model Order Selection Algorithm for Spectral Graph Clustering (ICASSP 2017)**
  - Pin-Yu Chen, Thibaut Gensollen, and Alfred O. Hero III 
  - [[Paper]](https://arxiv.org/abs/1609.06457)
  - [[Python Reference]](https://github.com/tgensol/AMOS)

One of the longstanding problems in spectral graph clustering (SGC) is the so-called model order selection problem: automated selection of the correct number of clusters. This is equivalent to the problem of finding the number of connected components or communities in an undirected graph. In this paper, we propose AMOS, an automated model order selection algorithm for SGC. Based on a recent analysis of clustering reliability for SGC under the random interconnection model, AMOS works by incrementally increasing the number of clusters, estimating the quality of identified clusters, and providing a series of clustering reliability tests. Consequently, AMOS outputs clusters of minimal model order with statistical clustering reliability guarantees. Comparing to three other automated graph clustering methods on real-world datasets, AMOS shows superior performance in terms of multiple external and internal clustering metrics.

- **18.Enhanced Community Detection in Social Networks Using Active Spectral Clustering (SAC 2016)**
  - Sarah Habashi, Nagia M. Ghanem, and Mohamed A. Ismail
  - [[Paper]](https://dl.acm.org/citation.cfm?id=2851987)
  - [[Matlab Reference]](https://github.com/sarahelhammadi/CDASC)

Detecting community structure is a fundamental problem in social networks analysis. In this paper, an enhanced semi-supervised approach to community detection using active spectral clustering is proposed. This approach incorporates partial background knowledge in the form of pairwise must-link and cannot-link constraints into community detection. It achieves significant performance improvement using fewer constraints by actively selecting the most informative constraints and querying human expert for them. The constraints are incorporated into spectral clustering by adjusting the pairwise similarity matrix accordingly. Experimental results on benchmark synthetic and real world social networks show that this approach significantly outperforms recent semi-supervised algorithms for community detection in terms of the Normalized Mutual Information (NMI) achieved with respects to the percentage of constraints used.

- **19.Clustering Signed Networks with the Geometric Mean of Laplacians (NIPS 2016)**
  - Pedro Mercado, Francesco Tudisco, and Matthias Hein
  - [[Paper]](http://papers.nips.cc/paper/6164-clustering-signed-networks-with-the-geometric-mean-of-laplacians.pdf)
  - [[Matlab Reference]](https://github.com/melopeo/GM)

Signed networks allow to model positive and negative relationships. We analyze
existing extensions of spectral clustering to signed networks. It turns out that
existing approaches do not recover the ground truth clustering in several situations
where either the positive or the negative network structures contain no noise. Our
analysis shows that these problems arise as existing approaches take some form of
arithmetic mean of the Laplacians of the positive and negative part. As a solution
we propose to use the geometric mean of the Laplacians of positive and negative
part and show that it outperforms the existing approaches. While the geometric
mean of matrices is computationally expensive, we show that eigenvectors of the
geometric mean can be computed efficiently, leading to a numerical scheme for
sparse matrices which is of independent interest.


- **20.Spectral Clustering with Graph Filtering and Landmark Based Representation (ICASSP 2016)**
  - Nicolas Tremblay, Gilles Puy, Pierre Borgnat, Rémi Gribonval, and Pierre Vandergheynst
  - [[Paper]](https://arxiv.org/pdf/1509.08863.pdf)
  - [[Python Reference]](https://github.com/cylindricalcow/FastSpectralClustering)

We build upon recent advances in graph signal processing to
propose a faster spectral clustering algorithm. Indeed, classical spectral clustering is based on the computation of the
first k eigenvectors of the similarity matrix’ Laplacian, whose
computation cost, even for sparse matrices, becomes prohibitive for large datasets. We show that we can estimate the
spectral clustering distance matrix without computing these
eigenvectors: by graph filtering random signals. Also, we
take advantage of the stochasticity of these random vectors to
estimate the number of clusters k. We compare our method to
classical spectral clustering on synthetic data, and show that
it reaches equal performance while being faster by a factor at
least two for large datasets

- **21.Uncovering the Small Community Structure in Large Networks: a Local Spectral Approach (WWW 2015)**
  - Li Yixuan, He Kun, David Bindel, and John Hopcroft
  - [[Paper]](https://arxiv.org/abs/1509.07715)
  - [[Python Reference]](https://github.com/YixuanLi/LEMON)

Large graphs arise in a number of contexts and understanding their structure and extracting information from them is an important research area. Early algorithms on mining communities have focused on the global structure, and often run in time functional to the size of the entire graph. Nowadays, as we often explore networks with billions of vertices and find communities of size hundreds, it is crucial to shift our attention from macroscopic structure to microscopic structure when dealing with large networks. A growing body of work has been adopting local expansion methods in order to identify the community from a few exemplary seed members.
In this paper, we propose a novel approach for finding overlapping communities called LEMON (Local Expansion via Minimum One Norm). Different from PageRank-like diffusion methods, LEMON finds the community by seeking a sparse vector in the span of the local spectra such that the seeds are in its support. We show that LEMON can achieve the highest detection accuracy among state-of-the-art proposals. The running time depends on the size of the community rather than that of the entire graph. The algorithm is easy to implement, and is highly parallelizable.
Moreover, given that networks are not all similar in nature, a comprehensive analysis on how the local expansion approach is suited for uncovering communities in different networks is still lacking. We thoroughly evaluate our approach using both synthetic and real-world datasets across different domains, and analyze the empirical variations when applying our method to inherently different networks in practice. In addition, the heuristics on how the quality and quantity of the seed set would affect the performance are provided.

- **22.Large-Scale Multi-View Spectral Clustering via Bipartite Graph (AAAI 2015)**
  - Yeqing Li, Feiping Nie, Heng Huang, and Junzhou Huang
  - [[Paper]](https://pdfs.semanticscholar.org/9383/f08c697b8aa43782e16c9a57e089911584d8.pdf)
  - [[Matlab Reference]](https://github.com/zzz123xyz/MVSC)

 In this paper, we address the problem of large-scale multi-view spectral clustering. In many real-world applications, data can be represented in various heterogeneous features or views. Different views often provide different aspects of information that are complementary to each other. Several previous methods of clustering have demonstrated that better accuracy can be achieved using integrated information of all the views than just using each view individually. One important class of such methods is multi-view spectral clustering, which is based on graph Laplacian. However, existing methods are not applicable to large-scale problem for their high computational complexity. To this end, we propose a novel large-scale multi-view spectral clustering approach based on the bipartite graph. Our method uses local manifold fusion to integrate heterogeneous features. To improve efficiency, we approximate the similarity graphs using bipartite graphs. Furthermore, we show that our method can be easily extended to handle the out-of-sample problem. Extensive experimental results on five benchmark datasets demonstrate the effectiveness and efficiency of the proposed method, where our method runs up to nearly 3000 times faster than the state-of-the-art methods

- **23.Constructing Robust Affinity Graphs for Spectral Clustering (CVPR 2014)**
  - Xiatian Zhu1, Chen Change Loy, Shaogang Gong
  - [[Paper]](https://www.zpascal.net/cvpr2014/Zhu_Constructing_Robust_Affinity_2014_CVPR_paper.pdf)
  - [[Matlab Reference]](https://github.com/d12306/Constructing-Robust-Affinity-Graphs-for-Spectral-Clustering)

Spectral clustering requires robust and meaningful affinity graphs as input in order to form clusters with desired
structures that can well support human intuition. To construct such affinity graphs is non-trivial due to the ambiguity and uncertainty inherent in the raw data. In contrast to most existing clustering methods that typically employ all available features to construct affinity matrices with
the Euclidean distance, which is often not an accurate representation of the underlying data structures, we propose
a novel unsupervised approach to generating more robust
affinity graphs via identifying and exploiting discriminative
features for improving spectral clustering. Specifically, our
model is capable of capturing and combining subtle similarity information distributed over discriminative feature
subspaces for more accurately revealing the latent data distribution and thereby leading to improved data clustering,
especially with heterogeneous data sources. We demonstrate the efficacy of the proposed approach on challenging
image and video datasets.

- **24.Accurate Community Detection in the Stochastic Block Model via Spectral Algorithms (Arxiv 2014)**
  - Se-Young Yun, Alexandre Proutiere
  - [[Paper]](https://arxiv.org/abs/1412.7335)
  - [[R Reference]](https://github.com/Jantg/Community_Detection)

![image](https://raw.githubusercontent.com/JimWongM/ImageHost/master/img/20200408110646.png)



- **25.Self-Taught Spectral Clustering via Constraint Augmentation (SDM 2014)**
  - Xiang Wang, Jun Wang, Buyue Qian, Fei Wang and Ian Davidson
  - [[Paper]](https://epubs.siam.org/doi/pdf/10.1137/1.9781611973440.48)
  - [[Matlab Reference]](https://github.com/gnaixgnaw/CSP)

Although constrained spectral clustering has been used extensively for the past few years, all work assumes the guidance (constraints) are given by humans. Original formulations of the problem assumed the constraints are given passively whilst later work allowed actively polling an Oracle
(human experts). In this paper, for the first time to our
knowledge, we explore the problem of augmenting the given
constraint set for constrained spectral clustering algorithms.
This moves spectral clustering towards the direction of selfteaching as has occurred in the supervised learning literature. We present a formulation for self-taught spectral clustering and show that the self-teaching process can drastically
improve performance without further human guidance.


- **26.Multi-Objective Multi-View Spectral Clustering via Pareto Optimization (SDM 2013)**
  - Xiang Wang, Buyue Qian, Jieping Ye, and Ian Davidson
  - [[Paper]](http://www2.cs.uh.edu/~ceick/DM/P4_DM4.pdf)
  - [[Matlab Reference]](https://github.com/gnaixgnaw/CSP)

Traditionally, spectral clustering is limited to a single objective: finding the normalized min-cut of a single graph.
However, many real-world datasets, such as scientific data
(fMRI scans of different individuals), social data (different
types of connections between people), web data (multi-type
data), are generated from multiple heterogeneous sources.
How to optimally combine knowledge from multiple sources
to improve spectral clustering remains a developing area.
Previous work on multi-view clustering formulated the problem as a single objective function to optimize, typically by
combining the views under a compatibility assumption and
requiring the users to decide the importance of each view
a priori. In this work, we propose a multi-objective formulation and show how to solve it using Pareto optimization.
The Pareto frontier captures all possible good cuts without
requiring the users to set the “correct” parameter. The effectiveness of our approach is justified by both theoretical
analysis and empirical results. We also demonstrate a novel
application of our approach: resting-state fMRI analysis.

- **27.Co-Clustering for Directed Graphs: the Stochastic Co-Blockmodel and Spectral Algorithm Di-Sim (ArXiv 2012)**
  - Karl Rohe, Tai Qin, and Bin Yu
  - [[Paper]](https://arxiv.org/abs/1204.2296)
  - [[R Reference]](https://github.com/karlrohe/disim)
  
- **28.Asymptotic Analysis of the Stochastic Block Model for Modular Networks and its Algorithmic Applications (Physical Review 2011)**
  - Aurelien Decelle, Florent Krzakala, Cristopher Moore, and Lenka Zdeborova
  - [[Paper]](https://arxiv.org/abs/1109.3041)
  - [[C++ Reference]](https://github.com/junipertcy/sbm-bp)
  
- **29.Phase Transition in the Detection of Modules in Sparse Networks (Physical Review Letters 2011)**
  - Aurelien Decelle, Florent Krzakala, Cristopher Moore, and Lenka Zdeborova
  - [[Paper]](https://arxiv.org/abs/1102.1182)
  - [[C++ Reference]](https://github.com/junipertcy/sbm-bp)
  
- **30.Active Spectral Clustering (ICDM 2010)**
  - Xiang Wang and Ian Davidson
  - [[Paper]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.299.7661&rep=rep1&type=pdf)
  - [[Matlab Reference]](https://github.com/gnaixgnaw/CSP)

The technique of spectral clustering is widely used
to segment a range of data from graphs to images. Our
work marks a natural progression of spectral clustering from
the original passive unsupervised formulation to our active
semi-supervised formulation. We follow the widely used area
of constrained clustering and allow supervision in the form
of pairwise relations between two nodes: Must-Link and
Cannot-Link. Unlike most previous constrained clustering
work, our constraints are specified incrementally by querying
an oracle (domain expert). Since in practice, each query comes
with a cost, our goal is to maximally improve the result with
as few queries as possible. The advantages of our approach
include: 1) it is principled by querying the constraints which
maximally reduce the expected error; 2) it can incorporate
both hard and soft constraints which are prevalent in practice.
We empirically show that our method significantly outperforms
the baseline approach, namely constrained spectral clustering
with randomly selected constraints, on UCI benchmark data
sets.


- **31.Flexible Constrained Spectral Clustering (KDD 2010)**
  - Xiang Wang and Ian Davidson
  - [[Paper]](http://web.cs.ucdavis.edu/~davidson/Publications/rp058d-wang.pdf)
  - [[Matlab Reference]](https://github.com/gnaixgnaw/CSP)

Constrained clustering has been well-studied for algorithms
like K-means and hierarchical agglomerative clustering. However, how to encode constraints into spectral clustering remains a developing area. In this paper, we propose a flexible and generalized framework for constrained spectral clustering. In contrast to some previous efforts that implicitly
encode Must-Link and Cannot-Link constraints by modifying the graph Laplacian or the resultant eigenspace, we
present a more natural and principled formulation, which
preserves the original graph Laplacian and explicitly encodes
the constraints. Our method offers several practical advantages: it can encode the degree of belief (weight) in MustLink and Cannot-Link constraints; it guarantees to lowerbound how well the given constraints are satisfied using a
user-specified threshold; and it can be solved deterministically in polynomial time through generalized eigendecomposition. Furthermore, by inheriting the objective function
from spectral clustering and explicitly encoding the constraints, much of the existing analysis of spectral clustering techniques is still valid. Consequently our work can be
posed as a natural extension to unconstrained spectral clustering and be interpreted as finding the normalized min-cut
of a labeled graph. We validate the effectiveness of our approach by empirical results on real-world data sets, with applications to constrained image segmentation and clustering
benchmark data sets with both binary and degree-of-belief
constraints.


- **32.Spectral Clustering Based on the Graph p-Laplacian (ICML 2009)**
  - Thomas Buhler and  Matthias Hein 
  - [[Paper]](https://www.ml.uni-saarland.de/Publications/BueHei-pSpectralClustering2009.pdf)
  - [[Matlab Reference]](https://github.com/tbuehler/pSpectralClustering)
